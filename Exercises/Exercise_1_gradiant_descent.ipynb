{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for gradiant descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37454012, 0.95071431],\n",
       "       [1.        , 0.73199394, 0.59865848],\n",
       "       [1.        , 0.15601864, 0.15599452],\n",
       "       ...,\n",
       "       [1.        , 0.75137509, 0.65695516],\n",
       "       [1.        , 0.95661462, 0.06895802],\n",
       "       [1.        , 0.05705472, 0.28218707]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "array_index = 0\n",
    "samples = 1000\n",
    "x = np.random.rand(samples, 2)\n",
    "intercept = np.ones(samples)\n",
    "\n",
    "epsilon = np.random.randn(samples)\n",
    "\n",
    "for i in x:\n",
    "    y = 3*x[array_index][0] + 5*x[array_index][1] + 3 + epsilon\n",
    "    array_index +=1 \n",
    "\n",
    "x = np.c_[intercept, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3,1) doesn't match the broadcast shape (3,1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\FabianAndersson-AIU2\\Documents\\GitHub\\Machinelearning-Fabian-Andersson\\Exercises\\Exercise_1_gradiant_descent.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=7'>8</a>\u001b[0m         theta \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate\u001b[39m*\u001b[39mgradient\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m theta\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=11'>12</a>\u001b[0m theta \u001b[39m=\u001b[39m gradient_desecent(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=12'>13</a>\u001b[0m \u001b[39mlen\u001b[39m(theta)\n",
      "\u001b[1;32mc:\\Users\\FabianAndersson-AIU2\\Documents\\GitHub\\Machinelearning-Fabian-Andersson\\Exercises\\Exercise_1_gradiant_descent.ipynb Cell 4'\u001b[0m in \u001b[0;36mgradient_desecent\u001b[1;34m(X, y, learning_rate, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=6'>7</a>\u001b[0m     gradient \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m/\u001b[39m m \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (X \u001b[39m@\u001b[39m theta \u001b[39m-\u001b[39m y)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=7'>8</a>\u001b[0m     theta \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate\u001b[39m*\u001b[39mgradient\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/FabianAndersson-AIU2/Documents/GitHub/Machinelearning-Fabian-Andersson/Exercises/Exercise_1_gradiant_descent.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m theta\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (3,1) doesn't match the broadcast shape (3,1000)"
     ]
    }
   ],
   "source": [
    "def gradient_desecent(X, y, learning_rate=0.1, epochs=500):\n",
    "    m = len(X)\n",
    "\n",
    "    theta = np.random.randn(X.shape[1], 1)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        gradient = 2 / m * X.T @ (X @ theta - y)\n",
    "        theta -= learning_rate*gradient\n",
    "    \n",
    "    return theta\n",
    "\n",
    "theta = gradient_desecent(x, y)\n",
    "len(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74522788009941975a4274ce688126e1a7bad11a56dd47c92f86889bb9d598be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Machinelearning-Fabian-Andersson-w7oPBvBJ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
